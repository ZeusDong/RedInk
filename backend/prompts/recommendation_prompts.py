"""
æ¨èç³»ç»Ÿ AI æç¤ºè¯

ç”¨äºä»å·²åˆ†æçš„ç¬”è®°ä¸­æç‚¼å¯å­¦ä¹ çš„å…ƒç´ å’Œæ¨èç†ç”±
"""

import logging
from typing import Dict, Any, List

logger = logging.getLogger(__name__)


def format_insights_extraction_prompt(
    topic: str,
    analysis_content: str,
    record: Dict[str, Any]
) -> str:
    """
    æ ¼å¼åŒ– AI æç‚¼æç¤ºè¯

    Args:
        topic: ç”¨æˆ·æœç´¢çš„ä¸»é¢˜
        analysis_content: AI åˆ†æç»“æœï¼ˆ7å±‚æ‹†è§£å†…å®¹ï¼‰
        record: ç¬”è®°æ•°æ®å­—å…¸

    Returns:
        å®Œæ•´çš„ AI æç¤ºè¯
    """
    title = record.get('title', '')
    industry = record.get('industry', '')
    metrics = record.get('metrics', {})
    total_engagement = metrics.get('total_engagement', 0)

    prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å°çº¢ä¹¦å†…å®¹ç­–ç•¥ä¸“å®¶ï¼Œæ“…é•¿ä»ä¼˜è´¨ç¬”è®°ä¸­æç‚¼å¯å¤ç”¨çš„åˆ›ä½œå…ƒç´ ã€‚

## ç”¨æˆ·æœç´¢ä¸»é¢˜
{topic}

## ç¬”è®°åŸºæœ¬ä¿¡æ¯
- æ ‡é¢˜ï¼š{title}
- è¡Œä¸šï¼š{industry}
- æ€»äº’åŠ¨é‡ï¼š{total_engagement}

## AI æ·±åº¦åˆ†æï¼ˆ7å±‚æ‹†è§£ï¼‰
{analysis_content}

## ä»»åŠ¡è¦æ±‚
è¯·åŸºäºä»¥ä¸Šåˆ†æå†…å®¹ï¼Œæç‚¼ä»¥ä¸‹ä¿¡æ¯ï¼š

### 1. æ¨èç†ç”±ï¼ˆrecommend_reasonsï¼‰
æœ€å¤š3æ¡ï¼Œæ¯æ¡ä¸è¶…è¿‡30å­—ï¼Œå¿…é¡»æ˜¯ç”¨æˆ·å¯è¯»çš„è‡ªç„¶è¯­è¨€ï¼Œè¯´æ˜ä¸ºä»€ä¹ˆè¿™ä¸ªç¬”è®°å€¼å¾—å­¦ä¹ ã€‚
è€ƒè™‘ç»´åº¦ï¼š
- çˆ†æ¬¾é€»è¾‘ï¼šä¸ºä»€ä¹ˆèƒ½ç«ï¼Ÿ
- å†…å®¹ä»·å€¼ï¼šç”¨æˆ·è·å¾—ä»€ä¹ˆï¼Ÿ
- åˆ›ä½œæŠ€å·§ï¼šæœ‰å“ªäº›äº®ç‚¹ï¼Ÿ

### 2. å¯å­¦ä¹ å…ƒç´ ï¼ˆlearnable_elementsï¼‰
æç‚¼4ä¸ªç»´åº¦çš„å¯å¤ç”¨å…ƒç´ ï¼Œæ¯ä¸ªä¸è¶…è¿‡15å­—ï¼š

**a) é’©å­ç±»å‹ï¼ˆhookï¼‰**
å¼€å¤´ç”¨ä»€ä¹ˆæ–¹å¼å¸å¼•æ³¨æ„ï¼Ÿä¾‹å¦‚ï¼š
- æ•°å­—æ‚¬å¿µï¼š"3ä¸ªæŠ€å·§..."
- ç—›ç‚¹å…±é¸£ï¼š"ä½ æ˜¯ä¸æ˜¯ä¹Ÿ..."
- åˆ©ç›Šå‰ç½®ï¼š"æ•™ä½ çœé’±..."

**b) ç»“æ„æ¡†æ¶ï¼ˆstructureï¼‰**
å†…å®¹å¦‚ä½•ç»„ç»‡ï¼Ÿä¾‹å¦‚ï¼š
- é—®é¢˜-è§£å†³æ–¹æ¡ˆ
- å¯¹æ¯”æµ‹è¯„
- åˆ†æ­¥éª¤æ•™ç¨‹

**c) è¯­è¨€é£æ ¼ï¼ˆtoneï¼‰**
è¡¨è¾¾ç‰¹ç‚¹ï¼Ÿä¾‹å¦‚ï¼š
- å§å¦¹èŠå¤©å¼
- ä¸“ä¸šå¹²è´§å‹
- æç¬‘è½»æ¾é£

**d) äº’åŠ¨è®¾è®¡ï¼ˆctaï¼‰**
å¦‚ä½•å¼•å¯¼äº’åŠ¨ï¼Ÿä¾‹å¦‚ï¼š
- "ä½ è§‰å¾—å‘¢ï¼Ÿè¯„è®ºåŒºè§"
- "ç‚¹èµæ”¶è—ä¸è¿·è·¯"
- "è½¬å‘ç»™ä½ æœ€çˆ±çš„äºº"

## è¾“å‡ºæ ¼å¼
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼ˆä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡å­—ï¼‰ï¼š

```json
{{
  "recommend_reasons": [
    "æ¨èç†ç”±1",
    "æ¨èç†ç”±2",
    "æ¨èç†ç”±3"
  ],
  "learnable_elements": {{
    "hook": "é’©å­ç±»å‹",
    "structure": "ç»“æ„æ¡†æ¶",
    "tone": "è¯­è¨€é£æ ¼",
    "cta": "äº’åŠ¨è®¾è®¡"
  }}
}}
```

## æ³¨æ„äº‹é¡¹
1. å¿…é¡»åŸºäºåˆ†æç»“æœï¼Œä¸è¦ç¼–é€ 
2. è¯­è¨€è¦ç®€æ´ã€å‡†ç¡®ã€å¯æ“ä½œ
3. JSON å¿…é¡»æœ‰æ•ˆä¸”ç¬¦åˆæ ¼å¼
4. æ¯ä¸ªå…ƒç´ éƒ½è¦å…·ä½“ï¼Œä¸è¦ç”¨"å¾ˆå¥½"ã€"ä¸é”™"ç­‰ç©ºæ³›è¯æ±‡
"""

    return prompt


def parse_insights_response(response: str) -> Dict[str, Any]:
    """
    è§£æ AI è¿”å›çš„æç‚¼ç»“æœ

    Args:
        response: AI è¿”å›çš„æ–‡æœ¬

    Returns:
        è§£æåçš„ç»“æ„åŒ–æ•°æ®
    """
    import json
    import re

    # å°è¯•ç›´æ¥è§£æ JSON
    try:
        # æå– JSON ä»£ç å—
        json_match = re.search(r'```json\s*([\s\S]*?)\s*```', response)
        if json_match:
            json_str = json_match.group(1)
        else:
            # å°è¯•æ‰¾çº¯ JSON
            json_match = re.search(r'\{[\s\S]*\}', response)
            if json_match:
                json_str = json_match.group(0)
            else:
                json_str = response

        data = json.loads(json_str)

        # éªŒè¯å¿…éœ€å­—æ®µ
        if 'recommend_reasons' not in data or 'learnable_elements' not in data:
            raise ValueError("Missing required fields in AI response")

        return {
            'recommend_reasons': data['recommend_reasons'][:3],  # æœ€å¤š3æ¡
            'learnable_elements': data['learnable_elements'],
            'extracted_at': None  # å°†åœ¨ä¿å­˜æ—¶è®¾ç½®
        }

    except (json.JSONDecodeError, ValueError) as e:
        logger.warning(f"Failed to parse AI insights response: {e}, using fallback")

        # é™çº§ï¼šè§„åˆ™æå–
        return fallback_insights_extraction(response)


def fallback_insights_extraction(response: str) -> Dict[str, Any]:
    """
    é™çº§ç­–ç•¥ï¼šä»éç»“æ„åŒ–æ–‡æœ¬ä¸­æå–æ´å¯Ÿ

    Args:
        response: AI è¿”å›çš„æ–‡æœ¬

    Returns:
        ç»“æ„åŒ–æ•°æ®ï¼ˆå¯èƒ½ä¸å®Œæ•´ï¼‰
    """
    import re

    reasons = []
    elements = {'hook': '', 'structure': '', 'tone': '', 'cta': ''}

    # å°è¯•æå–æ¨èç†ç”±
    reason_patterns = [
        r'æ¨èç†ç”±\d*[ï¼š:]\s*([^\n]+)',
        r'recommend_reasons?\d*[ï¼š:]\s*([^\n]+)',
        r'ä¸ºä»€ä¹ˆ[ï¼š:]\s*([^\n]+)',
    ]
    for pattern in reason_patterns:
        matches = re.findall(pattern, response)
        for match in matches:
            reason = match.strip()[:30]  # é™åˆ¶é•¿åº¦
            if reason and len(reasons) < 3:
                reasons.append(reason)

    # å°è¯•æå–é’©å­
    hook_patterns = [
        r'é’©å­\d*[ï¼š:]\s*([^\n]+)',
        r'hook\d*[ï¼š:]\s*([^\n]+)',
    ]
    for pattern in hook_patterns:
        match = re.search(pattern, response)
        if match:
            elements['hook'] = match.group(1).strip()[:15]
            break

    # å°è¯•æå–ç»“æ„
    structure_patterns = [
        r'ç»“æ„\d*[ï¼š:]\s*([^\n]+)',
        r'structure\d*[ï¼š:]\s*([^\n]+)',
    ]
    for pattern in structure_patterns:
        match = re.search(pattern, response)
        if match:
            elements['structure'] = match.group(1).strip()[:15]
            break

    # å°è¯•æå–é£æ ¼
    tone_patterns = [
        r'é£æ ¼\d*[ï¼š:]\s*([^\n]+)',
        r'tone\d*[ï¼š:]\s*([^\n]+)',
    ]
    for pattern in tone_patterns:
        match = re.search(pattern, response)
        if match:
            elements['tone'] = match.group(1).strip()[:15]
            break

    # å°è¯•æå–äº’åŠ¨è®¾è®¡
    cta_patterns = [
        r'äº’åŠ¨\d*[ï¼š:]\s*([^\n]+)',
        r'cta\d*[ï¼š:]\s*([^\n]+)',
    ]
    for pattern in cta_patterns:
        match = re.search(pattern, response)
        if match:
            elements['cta'] = match.group(1).strip()[:15]
            break

    # å¦‚æœæ²¡æœ‰æå–åˆ°æ¨èç†ç”±ï¼Œä½¿ç”¨é€šç”¨ç†ç”±
    if not reasons:
        reasons = [
            "å†…å®¹è´¨é‡é«˜ï¼Œç»“æ„æ¸…æ™°",
            "æ•°æ®è¡¨ç°ä¼˜ç§€ï¼Œå€¼å¾—å­¦ä¹ "
        ]

    return {
        'recommend_reasons': reasons,
        'learnable_elements': elements,
        'extracted_at': None
    }


def format_match_score_display(score: float) -> str:
    """
    æ ¼å¼åŒ–åŒ¹é…åº¦æ˜¾ç¤ºæ–‡æœ¬

    Args:
        score: åŒ¹é…åˆ†æ•° 0-1

    Returns:
        æ˜¾ç¤ºæ–‡æœ¬
    """
    if score >= 0.7:
        return "ğŸ”¥ é«˜åº¦åŒ¹é…"
    elif score >= 0.4:
        return "ğŸ“Œ ç›¸å…³æ¨è"
    elif score >= 0.3:
        return "ğŸ’¡ å¯èƒ½ç›¸å…³"
    else:
        return "ğŸ“ ç›¸å…³å‚è€ƒ"


def calculate_match_level(score: float) -> str:
    """
    è®¡ç®—åŒ¹é…ç­‰çº§

    Args:
        score: åŒ¹é…åˆ†æ•° 0-1

    Returns:
        åŒ¹é…ç­‰çº§: high | medium | low
    """
    if score >= 0.7:
        return 'high'
    elif score >= 0.4:
        return 'medium'
    else:
        return 'low'


SEMANTIC_SCORING_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å°çº¢ä¹¦å†…å®¹æ¨èä¸“å®¶ï¼Œæ“…é•¿åˆ¤æ–­ç¬”è®°ä¸ç”¨æˆ·æœç´¢æ„å›¾çš„è¯­ä¹‰ç›¸å…³æ€§ã€‚

## ç”¨æˆ·æœç´¢ä¸»é¢˜
{topic}

## å€™é€‰ç¬”è®°åˆ—è¡¨
{candidates}

## è¯„åˆ†ç»´åº¦

### 1. ä¸»é¢˜ç›¸å…³åº¦ï¼ˆ0-10åˆ†ï¼‰
- 10åˆ†ï¼šå†…å®¹ä¸»é¢˜ä¸æœç´¢è¯é«˜åº¦ä¸€è‡´ï¼Œå®Œå…¨ç¬¦åˆç”¨æˆ·æ„å›¾
- 7-9åˆ†ï¼šä¸»é¢˜ç›¸å…³ï¼Œç•¥æœ‰åå·®ä½†ä»æœ‰å‚è€ƒä»·å€¼
- 4-6åˆ†ï¼šä¸»é¢˜æœ‰ä¸€å®šå…³è”ï¼Œä½†å­˜åœ¨æ˜æ˜¾å·®å¼‚
- 1-3åˆ†ï¼šä¸»é¢˜å‹‰å¼ºç›¸å…³ï¼Œå‚è€ƒä»·å€¼æœ‰é™
- 0åˆ†ï¼šå®Œå…¨ä¸ç›¸å…³

### 2. ç›®æ ‡ç”¨æˆ·åŒ¹é…åº¦ï¼ˆ0-10åˆ†ï¼‰
è¯„ä¼°ç›®æ ‡å—ä¼—æ˜¯å¦ä¸€è‡´ï¼šæ€§åˆ«ã€å¹´é¾„å±‚ã€æ¶ˆè´¹èƒ½åŠ›ã€èº«ä»½å®šä½ç­‰ã€‚
ä¾‹å¦‚ï¼š"ç”·å£«ç©¿æ­" vs "å¾¡å§é£" = 0-2åˆ†ï¼›"èŒåœºå°ç™½" vs "èµ„æ·±é«˜ç®¡" = ä½åˆ†

### 3. å†…å®¹é£æ ¼é€‚é…æ€§ï¼ˆ0-10åˆ†ï¼‰
è¯„ä¼°è¡¨è¾¾é£æ ¼ã€è°ƒæ€§æ˜¯å¦é€‚åˆä½œä¸ºåˆ›ä½œå‚è€ƒã€‚åŒ…æ‹¬ï¼šè¯­æ°”é£æ ¼ã€å†…å®¹ç»“æ„ã€è§†è§‰é£æ ¼ç­‰ã€‚

### 4. æ•°æ®è¡¨ç°åŠ åˆ†ï¼ˆ0-5åˆ†ï¼‰
é«˜äº’åŠ¨é‡ç¬”è®°é¢å¤–åŠ åˆ†ï¼Œä½œä¸ºå‚è€ƒä»·å€¼çš„è¾…åŠ©åˆ¤æ–­ã€‚

## è¾“å‡ºè¦æ±‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼ˆä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡å­—ï¼‰ï¼š

```json
{{
  "scores": [
    {{"record_id": "xxx", "ä¸»é¢˜ç›¸å…³åº¦": 8, "ç›®æ ‡ç”¨æˆ·åŒ¹é…åº¦": 2, "å†…å®¹é£æ ¼é€‚é…æ€§": 7, "æ•°æ®è¡¨ç°åŠ åˆ†": 3}},
    {{"record_id": "yyy", "ä¸»é¢˜ç›¸å…³åº¦": 6, "ç›®æ ‡ç”¨æˆ·åŒ¹é…åº¦": 9, "å†…å®¹é£æ ¼é€‚é…æ€§": 8, "æ•°æ®è¡¨ç°åŠ åˆ†": 4}}
  ]
}}
```

## æ³¨æ„äº‹é¡¹
1. å¿…é¡»ä¸ºæ¯ä¸ªå€™é€‰ç¬”è®°æ‰“åˆ†ï¼Œä¸èƒ½é—æ¼
2. åˆ†æ•°è¦å®¢è§‚ã€å‡†ç¡®ï¼Œä¸è¦éšæ„æ‰“é«˜åˆ†
3. è€ƒè™‘å°çº¢ä¹¦å¹³å°çš„å†…å®¹ç‰¹ç‚¹å’Œç”¨æˆ·éœ€æ±‚
"""


def format_semantic_scoring_prompt(topic: str, candidates: List[Dict[str, Any]]) -> str:
    """
    Format semantic scoring prompt with actual data.

    Args:
        topic: User's search topic
        candidates: List of candidate records with summary info

    Returns:
        Formatted prompt string
    """
    # Build candidate summary list with rich context
    candidate_lines = []
    for i, cand in enumerate(candidates, 1):
        record_id = cand.get('record_id', '')
        title = cand.get('title', '')[:50]  # Limit length
        industry = cand.get('industry', 'æœªçŸ¥')
        metrics = cand.get('metrics', {})
        engagement = metrics.get('total_engagement', 0)

        # Get insights for better context
        recommend_reasons = cand.get('recommend_reasons', [])
        learnable_elements = cand.get('learnable_elements', {})

        # Format insights
        reasons_text = '; '.join(recommend_reasons[:2]) if recommend_reasons else 'æ— '

        elements_list = []
        for key in ['ç›®æ ‡å—ä¼—', 'å†…å®¹ç»“æ„', 'è§†è§‰é£æ ¼', 'äº’åŠ¨è®¾è®¡', 'æ ¸å¿ƒå–ç‚¹', 'å­¦ä¹ è¦ç‚¹']:
            val = learnable_elements.get(key, '')
            if val:
                elements_list.append(f"{key}:{val}")

        elements_text = '; '.join(elements_list) if elements_list else 'æ— '

        line = (
            f"{i}. record_id: {record_id}\n"
            f"   æ ‡é¢˜: {title}\n"
            f"   è¡Œä¸š: {industry} | äº’åŠ¨é‡: {engagement}\n"
            f"   æ¨èç†ç”±: {reasons_text}\n"
            f"   å­¦ä¹ è¦ç‚¹: {elements_text}"
        )
        candidate_lines.append(line)

    candidates_text = "\n\n".join(candidate_lines)

    return SEMANTIC_SCORING_PROMPT.format(topic=topic, candidates=candidates_text)


def parse_semantic_scoring_response(response: str) -> Dict[str, Dict[str, Any]]:
    """
    Parse AI semantic scoring response.

    Args:
        response: AI returned text

    Returns:
        Dict mapping record_id to scores dict
    """
    import json
    import re

    # Try to parse JSON from code block
    json_match = re.search(r'```json\s*([\s\S]*?)\s*```', response)
    if json_match:
        json_str = json_match.group(1)
    else:
        # Try to find pure JSON
        json_match = re.search(r'\{[\s\S]*\}', response)
        if json_match:
            json_str = json_match.group(0)
        else:
            raise ValueError("No valid JSON found in AI response")

    try:
        data = json.loads(json_str)

        if 'scores' not in data:
            raise ValueError("Missing 'scores' field in AI response")

        # Convert to dict: {record_id: scores_dict}
        scores_by_id = {}
        for item in data['scores']:
            record_id = item.get('record_id')
            if record_id:
                scores_by_id[record_id] = {
                    'topic_relevance': item.get('ä¸»é¢˜ç›¸å…³åº¦', 0),
                    'audience_match': item.get('ç›®æ ‡ç”¨æˆ·åŒ¹é…åº¦', 0),
                    'style_fit': item.get('å†…å®¹é£æ ¼é€‚é…æ€§', 0),
                    'performance_bonus': item.get('æ•°æ®è¡¨ç°åŠ åˆ†', 0)
                }

        return scores_by_id

    except json.JSONDecodeError as e:
        raise ValueError(f"Failed to parse JSON response: {e}")


def calculate_final_score(scores: Dict[str, Any]) -> float:
    """
    Calculate final weighted score from AI dimensions.

    Weight distribution:
    - Topic relevance: 40%
    - Audience match: 30%
    - Style fit: 20%
    - Performance bonus: 10%

    Args:
        scores: Dict with topic_relevance, audience_match, style_fit, performance_bonus

    Returns:
        Final weighted score (0-10)
    """
    return round(
        scores.get('topic_relevance', 0) * 0.4 +
        scores.get('audience_match', 0) * 0.3 +
        scores.get('style_fit', 0) * 0.2 +
        scores.get('performance_bonus', 0) * 0.1,
        2
    )
